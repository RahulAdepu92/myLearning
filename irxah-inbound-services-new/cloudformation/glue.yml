# @Author : Rahul Adepu
# This yml script deploys glue jobs and associated triggers if any by creating a stack "MyGlueStack"
# Note: 1. prior to execution of this yml, glue scripts need to be placed in <ScriptLocation> and the latest wheel file should be in path <extra-py-files>
#       2. deployment would be taken care by a single command(read "repo/deploy-sit.ps1") when run in AWS CLI and the paramteres are dynamaically changed as per environment there
#       3. If you make any code changes in "GlueJob1", just upload the latest script to s3 and rerun existing "MyGlueStack" which overrides "GlueJob1" with new code leaving the #          other glue jobs unchanged
# Challenges faced: adding a wheel file to the resource --> declare '--extra-py-files' in "DefaultArguments" property

AWSTemplateFormatVersion: '2010-09-09'
Description: 'Accumhub Lambda Glue Formation Template'

####### Declaring parameters below-

Parameters:
  accountProfile:
    Description: provides the AWS account number as per enviroment
    Type: String
    Default: 795038802291
  glueRoleArn:
    Description: provides ARN of glue role that provides permissions to execute Glue jobs
    Type: String
    Default: arn:aws:iam::795038802291:role/irx-accum-glue-role
  redshiftGlueArn:
    Type: String
    Default: arn:aws:iam::795038802291:role/irx-accum-phi-redshift-glue
    Description: provides ARN of redshift-glue role that provides permissions to run execute copy/unload commands in redshift database
  scriptsPath:
    Type: String
    Default: irx-accumhub-dev-data/deployment
    Description: provides the bucket name where glue scripts, .whl and .zip needed for both Glue jobs and Lamda functions are resided
  dataBucket:
    Type: String
    Default: irx-accumhub-dev-data
    Description: provides the bucket name where the incoming/outgoing files data is processed and stored.
  wheelVersion:
    Description: provides version number of .whl file that is used for Glue job execution
    Type: String
    Default: 0.1
  dbConnection:
    Description: provides connection name that is used to access redshift database while running Glue jobs
    Type: String
    Default: irx-accums-phi-rds-clr
  nameSuffix:
    Description: provides suffix to each glue job/lambda function that varies from run to run. This will be useful to distinguish developer specific function while testing his code.
    Type: String
    Default: _mvp2
  namePrefix:
    Description: provides prefix to each glue job/lambda function that varies from run to run. This will be useful to distinguish developer specific function while testing his code.
    Type: String
    Default: irxah_
  tagEnvironment:
    Description: provides the environment name whose value will be replaced in few tags and also utilised by some environment variables in functions/jobs.
    Type: String
    Default: DEV
  fileNameEnvironment:
    Description: provides the environment name whose value will be replaced in incoming/outgoing file names in function variables
    Type: String
    Default: TST
  deploymentEnvironment:
    Description: provides the environment name where deployment is happening and is used as environment variable by many functions
    Type: String
    Default: SIT
  fileType:
    Description: provides the environment name whose value will be replaced in environment variables in functions/jobs.
    Type: String
    Default: T
  secretManager:
    Description: complete name of the secret manager service that provides credentails for connecting to redshift database
    Type: String
    Default: irx-ahub-dv-redshift-cluster
  tagRegion:
    Description: provides the global region of AWS account used in tags
    Type: String
    Default: AWS -East 1
  enableTrigger:
    Description: decides if the trigger should be in activated or deactivated during initial deployment. Note that its value cant be regulated
                 and changed for intermittent deployments. For example, if you deploy a trigger  with value TRUE for the first time, it stays
                 TRUE forever. One cant modify its value to FALSE for next deployment via CFT.
    Type: String
    Default: true
  glueRunRetries:
    Description: provides the number of retry attempts that a glue job can make when failure occurs
    Type: String
    Default: 1

####### Adding Glue Jobs below-

Resources:
  processIncomingFileLoadInDatabase:
    Type: AWS::Glue::Job
    #DeletionPolicy: Retain     ##enable this option if you need this resource to remain alive when you delete the stack
    Properties:
      Command:
        Name: pythonshell
        PythonVersion: 3
        ScriptLocation: !Sub s3://${scriptsPath}/glue/irxah_process_incoming_file_load_in_database.py
      ExecutionProperty:
        MaxConcurrentRuns: 100
      DefaultArguments:
        --extra-py-files: !Sub s3://${scriptsPath}/irxah_common-${wheelVersion}-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/better_exceptions-0.2.2-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/croniter-0.3.36-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/frosch-0.1.6-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/natsort-7.1.0-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/pg8000-1.16.6-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/PySnooper-0.4.2-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/python_dateutil-2.8.1-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/scramp-1.2.0-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/six-1.15.0-py2.py3-none-any.whl
        #set these variables as per development requirement; developer has control over these values
      MaxCapacity: 1
      Timeout: 2880
      MaxRetries: !Ref glueRunRetries
      GlueVersion: 1.0
      Name: !Sub ${namePrefix}process_incoming_file_load_in_database${nameSuffix}
      Role: !Ref glueRoleArn
      Connections:
        Connections:
          - !Ref dbConnection
      Tags : { BarometerIT : 041800001L7T , Company : IRX , Opt In/Opt Out : Yes , Date/Time : 20200318101010 , Application Runtime Platform : Python 3.7 , COSTCENTER : 6590196400 , COMPLIANCE : PHI , Layer : ETL , Owner Department : Saneeja Abdeen , NAME: !Sub 'IRX-AHUB-GLUE-${tagEnvironment}-ETL' , Resource Type : GLUE , Database : RedShift , Virtualization Platform : N/A , Environment : !Ref tagEnvironment , Operating System : N/A , Location : !Ref tagRegion }

  processCvsFile:
    Type: AWS::Glue::Job
    #DeletionPolicy: Retain     ##enable this option if you need this resource to remain alive when you delete the stack
    Properties:
      Command:
        Name: pythonshell
        PythonVersion: 3
        ScriptLocation: !Sub s3://${scriptsPath}/glue/irxah_process_incoming_file_load_in_database.py
      ExecutionProperty:
        MaxConcurrentRuns: 100
      DefaultArguments:
        --extra-py-files: !Sub s3://${scriptsPath}/irxah_common-${wheelVersion}-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/better_exceptions-0.2.2-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/croniter-0.3.36-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/frosch-0.1.6-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/natsort-7.1.0-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/pg8000-1.16.6-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/PySnooper-0.4.2-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/python_dateutil-2.8.1-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/scramp-1.2.0-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/six-1.15.0-py2.py3-none-any.whl
      MaxCapacity: 1
      Timeout: 2880
      MaxRetries: !Ref glueRunRetries
      GlueVersion: 1.0
      Name: !Sub ${namePrefix}process_incoming_cvs_file${nameSuffix}
      Role: !Ref glueRoleArn
      Connections:
        Connections:
          - !Ref dbConnection
      Tags : { BarometerIT : 041800001L7T , Company : IRX , Opt In/Opt Out : Yes , Date/Time : 20200318101010 , Application Runtime Platform : Python 3.7 , COSTCENTER : 6590196400 , COMPLIANCE : PHI , Layer : ETL , Owner Department : Saneeja Abdeen , NAME: !Sub 'IRX-AHUB-GLUE-${tagEnvironment}-ETL' , Resource Type : GLUE , Database : RedShift , Virtualization Platform : N/A , Environment : !Ref tagEnvironment , Operating System : N/A , Location : !Ref tagRegion }

  exportClientFileManually:
    Type: AWS::Glue::Job
    #DeletionPolicy: Retain     ##enable this option if you need this resource to remain alive when you delete the stack
    Properties:
      Command:
        Name: pythonshell
        PythonVersion: 3
        ScriptLocation: !Sub s3://${scriptsPath}/glue/irxah_process_cvs_file_manually.py
      ExecutionProperty:
        MaxConcurrentRuns: 100
      DefaultArguments:
        --extra-py-files: !Sub s3://${scriptsPath}/irxah_common-${wheelVersion}-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/better_exceptions-0.2.2-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/croniter-0.3.36-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/frosch-0.1.6-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/natsort-7.1.0-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/pg8000-1.16.6-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/PySnooper-0.4.2-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/python_dateutil-2.8.1-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/scramp-1.2.0-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/six-1.15.0-py2.py3-none-any.whl
        #set these variables as per development requirement; developer has control over these values
        # below ids are daily outbounds are needed to be sent when cvs sends us less than 12 files
        # cfd= 13 has been removed from this list since it is a biweekly file https://jira.ingenio-rx.com/browse/AHUB-813
        # so Aetna outbound alone must be sent separately if cvs file count fall short on its outgoing schedule day
        --CLIENT_FILE_IDS: 4, 5, 15, 17, 20, 21
        --SECRET_NAME: !Ref secretManager
        --HELP_TEXT: Specify time or list of file names. Please put NA in parameters if you do not want to use it. List of client file ids can be varied as per requirement.
        --START_TIME_IN_24_HOUR_FORMAT_LOCAL: Specify the time in the respective local time zone in 24 hour format in mm/dd/yyyy hh24:mi:ss here.
        --END_TIME_IN_24_HOUR_FORMAT_LOCAL: Specify the time in the respective local time zone in 24 hour format in mm/dd/yyyy hh24:mi:ss here.
        --LIST_OF_CVS_FILE_NAMES: List of files that needs to be marked as Available to be sent to BCI
        --GLUE_JOB_TO_RUN: !Ref exportClientFile
      MaxCapacity: 1
      Timeout: 2880
      #MaxRetries: 0 # commented because manual job run dont require retry option. Job fails only if you pass inadequate parameters.
      GlueVersion: 1.0
      Name: !Sub  ${namePrefix}export_client_file_manually${nameSuffix}
      Role: !Ref glueRoleArn
      Connections:
        Connections:
          - !Ref dbConnection
      Tags : { BarometerIT : 041800001L7T , Company : IRX , Opt In/Opt Out : Yes , Date/Time : 20200318101010 , Application Runtime Platform : Python 3.7 , COSTCENTER : 6590196400 , COMPLIANCE : PHI , Layer : ETL , Owner Department : Saneeja Abdeen , NAME: !Sub 'IRX-AHUB-GLUE-${tagEnvironment}-ETL' , Resource Type : GLUE , Database : RedShift , Virtualization Platform : N/A , Environment : !Ref tagEnvironment , Operating System : N/A , Location : !Ref tagRegion }

  exportClientFile:
    Type: AWS::Glue::Job
    #DeletionPolicy: Retain     ##enable this option if you need this resource to remain alive when you delete the stack
    Properties:
      Command:
        Name: pythonshell
        PythonVersion: 3
        ScriptLocation: !Sub s3://${scriptsPath}/glue/irxah_export_client_file.py
      ExecutionProperty:
        MaxConcurrentRuns: 100
      DefaultArguments:
        --extra-py-files: !Sub s3://${scriptsPath}/irxah_common-${wheelVersion}-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/better_exceptions-0.2.2-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/croniter-0.3.36-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/frosch-0.1.6-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/natsort-7.1.0-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/pg8000-1.16.6-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/PySnooper-0.4.2-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/python_dateutil-2.8.1-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/scramp-1.2.0-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/six-1.15.0-py2.py3-none-any.whl
        #set these variables as per development requirement; developer has control over these values
        --SECRET_NAME: !Ref secretManager
        --S3_FILE_BUCKET: !Ref dataBucket
        --FILE_SCHEDULE_ID: 0
        --CLIENT_FILE_ID: -1
        --UPDATE_FILE_SCHEDULE_STATUS: "FALSE"
      MaxCapacity: 1
      Timeout: 2880
      MaxRetries:  !Ref glueRunRetries
      GlueVersion: 1.0
      Name: !Sub  ${namePrefix}export_client_file${nameSuffix}
      Role: !Ref glueRoleArn
      Connections:
        Connections:
          - !Ref dbConnection
      Tags : { BarometerIT : 041800001L7T , Company : IRX , Opt In/Opt Out : Yes , Date/Time : 20200318101010 , Application Runtime Platform : Python 3.7 , COSTCENTER : 6590196400 , COMPLIANCE : PHI , Layer : ETL , Owner Department : Saneeja Abdeen , NAME: !Sub 'IRX-AHUB-GLUE-${tagEnvironment}-ETL' , Resource Type : GLUE , Database : RedShift , Virtualization Platform : N/A , Environment : !Ref tagEnvironment , Operating System : N/A , Location : !Ref tagRegion }

  processCustomFile:
    Type: AWS::Glue::Job
    #DeletionPolicy: Retain     ##enable this option if you need this resource to remain alive when you delete the stack
    Properties:
      Command:
        Name: pythonshell
        PythonVersion: 3
        ScriptLocation: !Sub s3://${scriptsPath}/glue/irxah_process_custom_file.py
      ExecutionProperty:
        MaxConcurrentRuns: 100
      DefaultArguments:
        --extra-py-files: !Sub s3://${scriptsPath}/irxah_common-${wheelVersion}-py3-none-any.whl,
          s3://${scriptsPath}/supplemental-libraries/better_exceptions-0.2.2-py3-none-any.whl,
          s3://${scriptsPath}/supplemental-libraries/croniter-0.3.36-py2.py3-none-any.whl,
          s3://${scriptsPath}/supplemental-libraries/frosch-0.1.6-py3-none-any.whl,
          s3://${scriptsPath}/supplemental-libraries/natsort-7.1.0-py3-none-any.whl,
          s3://${scriptsPath}/supplemental-libraries/pg8000-1.16.6-py3-none-any.whl,
          s3://${scriptsPath}/supplemental-libraries/PySnooper-0.4.2-py2.py3-none-any.whl,
          s3://${scriptsPath}/supplemental-libraries/python_dateutil-2.8.1-py2.py3-none-any.whl,
          s3://${scriptsPath}/supplemental-libraries/scramp-1.2.0-py3-none-any.whl,
          s3://${scriptsPath}/supplemental-libraries/six-1.15.0-py2.py3-none-any.whl
      MaxCapacity: 1
      Timeout: 2880
      MaxRetries: !Ref glueRunRetries
      GlueVersion: 1.0
      Name: !Sub ${namePrefix}process_incoming_custom_file${nameSuffix}
      Role: !Ref glueRoleArn
      Connections:
        Connections:
          - !Ref dbConnection
      Tags : { BarometerIT : 041800001L7T , Company : IRX , Opt In/Opt Out : Yes , Date/Time : 20200318101010 , Application Runtime Platform : Python 3.7 , COSTCENTER : 6590196400 , COMPLIANCE : PHI , Layer : ETL , Owner Department : Saneeja Abdeen , NAME: !Sub 'IRX-AHUB-GLUE-${tagEnvironment}-ETL' , Resource Type : GLUE , Database : RedShift , Virtualization Platform : N/A , Environment : !Ref tagEnvironment , Operating System : N/A , Location : !Ref tagRegion }

  createWarmPool:
    Type: AWS::Glue::Job
    #DeletionPolicy: Retain     ##enable this option if you need this resource to remain alive when you delete the stack
    Properties:
      Command:
        Name: pythonshell
        PythonVersion: 3
        ScriptLocation: !Sub s3://${scriptsPath}/glue/irxah_create_warm_pool.py
      ExecutionProperty:
        MaxConcurrentRuns: 100
      DefaultArguments:
        --extra-py-files: !Sub s3://${scriptsPath}/irxah_common-${wheelVersion}-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/better_exceptions-0.2.2-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/croniter-0.3.36-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/frosch-0.1.6-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/natsort-7.1.0-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/pg8000-1.16.6-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/PySnooper-0.4.2-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/python_dateutil-2.8.1-py2.py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/scramp-1.2.0-py3-none-any.whl,
                               s3://${scriptsPath}/supplemental-libraries/six-1.15.0-py2.py3-none-any.whl
        #set these variables as per development requirement; developer has control over these values
      MaxCapacity: 1
      Timeout: 2880
      MaxRetries: !Ref glueRunRetries
      GlueVersion: 1.0
      Name: !Sub ${namePrefix}create_warm_pool${nameSuffix}
      Role: !Ref glueRoleArn
      Connections:
        Connections:
          - !Ref dbConnection
      Tags : { BarometerIT : 041800001L7T , Company : IRX , Opt In/Opt Out : Yes , Date/Time : 20200318101010 , Application Runtime Platform : Python 3.7 , COSTCENTER : 6590196400 , COMPLIANCE : PHI , Layer : ETL , Owner Department : Saneeja Abdeen , NAME: !Sub 'IRX-AHUB-GLUE-${tagEnvironment}-ETL' , Resource Type : GLUE , Database : RedShift , Virtualization Platform : N/A , Environment : !Ref tagEnvironment , Operating System : N/A , Location : !Ref tagRegion }


  createWarmPoolTrigger:
    #this is a scheduled trigger and points to the gluejob in resource "generateDailyFileFromCvsHourlyDataDeliverToBci"
    Type: AWS::Glue::Trigger
    #DeletionPolicy: Retain     ##enable this option if you need this resource to remain alive when you delete the stack
    Properties:
     Type: SCHEDULED
     Schedule: cron(58 0/1 * * ? *)
     Actions:
        - JobName: !Ref createWarmPool
     Name: !Sub ${namePrefix}create_warm_pool_trigger${nameSuffix}
     StartOnCreation: !Ref enableTrigger